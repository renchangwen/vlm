import React, { useState } from 'react';
import { FileText, Folder, Code, Terminal, Image, Zap } from 'lucide-react';

const ProjectStructure = () => {
  const [activeTab, setActiveTab] = useState('structure');

  const projectStructure = `text-guided-style-transfer/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ content/              # å†…å®¹å›¾ç‰‡
â”‚   â”‚   â”œâ”€â”€ landscape_1.jpg
â”‚   â”‚   â”œâ”€â”€ portrait_1.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ styles/               # é£æ ¼å›¾åº“
â”‚   â”‚   â”œâ”€â”€ vangogh_starry.jpg
â”‚   â”‚   â”œâ”€â”€ monet_water.jpg
â”‚   â”‚   â”œâ”€â”€ picasso_abstract.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ style_labels.json     # é£æ ¼å›¾æ–‡æœ¬æ ‡ç­¾
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ clip_retrieval.py     # CLIPæ£€ç´¢æ¨¡å—
â”‚   â”œâ”€â”€ adain.py              # AdaINæ ¸å¿ƒ
â”‚   â”œâ”€â”€ decoder.py            # è§£ç å™¨
â”‚   â””â”€â”€ vgg.py                # VGGç‰¹å¾æå–
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ image_processing.py   # å›¾åƒåŠ è½½/ä¿å­˜
â”‚   â””â”€â”€ visualization.py      # å¯è§†åŒ–å·¥å…·
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocess_styles.py  # é¢„å¤„ç†é£æ ¼ç‰¹å¾
â”‚   â”œâ”€â”€ train_decoder.py      # (å¯é€‰)è®­ç»ƒè§£ç å™¨
â”‚   â””â”€â”€ demo.py               # æ¼”ç¤ºè„šæœ¬
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ interactive_demo.ipynb # Jupyteræ¼”ç¤º
â”‚
â”œâ”€â”€ checkpoints/              # ä¿å­˜çš„æ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ decoder.pth
â”‚   â””â”€â”€ style_features.pt
â”‚
â”œâ”€â”€ results/                  # è¾“å‡ºç»“æœ
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ app.py                    # Gradio/Streamlitç•Œé¢`;

  const requirementsTxt = `# æ ¸å¿ƒä¾èµ–
torch>=2.0.0
torchvision>=0.15.0
clip @ git+https://github.com/openai/CLIP.git

# å›¾åƒå¤„ç†
Pillow>=9.0.0
opencv-python>=4.5.0
numpy>=1.21.0

# å¯è§†åŒ–
matplotlib>=3.5.0
seaborn>=0.11.0

# Webç•Œé¢
gradio>=3.50.0

# å·¥å…·
tqdm>=4.62.0
pyyaml>=6.0
scikit-learn>=1.0.0

# å¼€å‘å·¥å…·
jupyter>=1.0.0
ipython>=8.0.0`;

  const clipRetrievalCode = `import torch
import clip
from PIL import Image
import json
from pathlib import Path
from typing import Dict, Tuple, List

class CLIPStyleRetriever:
    """åŸºäºCLIPçš„é£æ ¼å›¾æ£€ç´¢å™¨"""
    
    def __init__(self, style_dir: str, device: str = "cuda"):
        self.device = device if torch.cuda.is_available() else "cpu"
        
        # åŠ è½½CLIPæ¨¡å‹
        self.model, self.preprocess = clip.load("ViT-B/32", device=self.device)
        self.model.eval()
        
        self.style_dir = Path(style_dir)
        self.style_features = {}
        
    def preprocess_style_library(self, style_labels_path: str, save_path: str = None):
        """é¢„å¤„ç†é£æ ¼å›¾åº“ï¼Œè®¡ç®—CLIPç‰¹å¾"""
        
        # åŠ è½½é£æ ¼å›¾æ ‡ç­¾
        with open(style_labels_path, 'r', encoding='utf-8') as f:
            style_labels = json.load(f)
        
        print("æ­£åœ¨é¢„å¤„ç†é£æ ¼å›¾åº“...")
        for img_name, text_label in style_labels.items():
            img_path = self.style_dir / img_name
            
            if not img_path.exists():
                print(f"è­¦å‘Š: {img_path} ä¸å­˜åœ¨")
                continue
            
            # åŠ è½½å›¾åƒ
            image = self.preprocess(Image.open(img_path)).unsqueeze(0).to(self.device)
            
            # ç¼–ç å›¾åƒå’Œæ–‡æœ¬
            with torch.no_grad():
                image_feature = self.model.encode_image(image)
                text_feature = self.model.encode_text(
                    clip.tokenize([text_label]).to(self.device)
                )
                
                # L2å½’ä¸€åŒ–
                image_feature = image_feature / image_feature.norm(dim=-1, keepdim=True)
                text_feature = text_feature / text_feature.norm(dim=-1, keepdim=True)
            
            self.style_features[img_name] = {
                'image_feature': image_feature.cpu(),
                'text_feature': text_feature.cpu(),
                'text_label': text_label,
                'path': str(img_path)
            }
            
            print(f"  å·²å¤„ç†: {img_name} - {text_label}")
        
        # ä¿å­˜ç‰¹å¾
        if save_path:
            torch.save(self.style_features, save_path)
            print(f"ç‰¹å¾å·²ä¿å­˜åˆ°: {save_path}")
        
        return self.style_features`;

  const adainCode = `import torch
import torch.nn as nn

class AdaIN(nn.Module):
    """Adaptive Instance Normalization"""
    
    def __init__(self):
        super().__init__()
    
    def forward(self, content_feat, style_feat):
        """
        Args:
            content_feat: (B, C, H, W) å†…å®¹ç‰¹å¾
            style_feat: (B, C, H', W') é£æ ¼ç‰¹å¾
        Returns:
            stylized_feat: (B, C, H, W) é£æ ¼åŒ–ç‰¹å¾
        """
        assert content_feat.size()[:2] == style_feat.size()[:2]
        
        B, C = content_feat.size()[:2]
        
        # è®¡ç®—å†…å®¹ç‰¹å¾çš„å‡å€¼å’Œæ ‡å‡†å·®
        content_mean = content_feat.view(B, C, -1).mean(dim=2).view(B, C, 1, 1)
        content_std = content_feat.view(B, C, -1).std(dim=2).view(B, C, 1, 1)
        
        # è®¡ç®—é£æ ¼ç‰¹å¾çš„å‡å€¼å’Œæ ‡å‡†å·®
        style_mean = style_feat.view(B, C, -1).mean(dim=2).view(B, C, 1, 1)
        style_std = style_feat.view(B, C, -1).std(dim=2).view(B, C, 1, 1)
        
        # æ ‡å‡†åŒ–å†…å®¹ç‰¹å¾
        normalized_feat = (content_feat - content_mean) / (content_std + 1e-5)
        
        # ä½¿ç”¨é£æ ¼ç»Ÿè®¡é‡é‡æ–°ç¼©æ”¾
        stylized_feat = normalized_feat * style_std + style_mean
        
        return stylized_feat`;

  const vggCode = `import torch
import torch.nn as nn
from torchvision.models import vgg19

class VGGEncoder(nn.Module):
    """ä½¿ç”¨VGG19ä½œä¸ºç¼–ç å™¨æå–ç‰¹å¾"""
    
    def __init__(self, device='cuda'):
        super().__init__()
        
        # åŠ è½½é¢„è®­ç»ƒçš„VGG19
        vgg = vgg19(pretrained=True)
        
        # ä½¿ç”¨relu4_1ä¹‹å‰çš„å±‚
        self.encoder = nn.Sequential(*list(vgg.features.children())[:21])
        
        # å†»ç»“å‚æ•°
        for param in self.encoder.parameters():
            param.requires_grad = False
        
        self.encoder.eval()
        self.encoder.to(device)`;

  const decoderCode = `import torch
import torch.nn as nn

class Decoder(nn.Module):
    """å°†AdaINç‰¹å¾è§£ç å›å›¾åƒ"""
    
    def __init__(self):
        super().__init__()
        
        # é•œåƒVGGç¼–ç å™¨çš„ç»“æ„
        self.decoder = nn.Sequential(
            nn.ReflectionPad2d(1),
            nn.Conv2d(512, 256, 3),
            nn.ReLU(inplace=True),
            
            nn.Upsample(scale_factor=2, mode='nearest'),
            nn.ReflectionPad2d(1),
            nn.Conv2d(256, 256, 3),
            nn.ReLU(inplace=True),
            
            nn.Upsample(scale_factor=2, mode='nearest'),
            nn.ReflectionPad2d(1),
            nn.Conv2d(128, 64, 3),
            nn.ReLU(inplace=True),
            
            nn.Upsample(scale_factor=2, mode='nearest'),
            nn.ReflectionPad2d(1),
            nn.Conv2d(64, 3, 3),
            nn.Sigmoid()
        )`;

  const pipelineCode = `from models.vgg import VGGEncoder
from models.adain import AdaIN
from models.decoder import Decoder
from models.clip_retrieval import CLIPStyleRetriever

class StyleTransferPipeline:
    """å®Œæ•´çš„æ–‡æœ¬å¼•å¯¼é£æ ¼è¿ç§»æµç¨‹"""
    
    def __init__(self, decoder_path: str, style_features_path: str, device: str = 'cuda'):
        self.device = device if torch.cuda.is_available() else 'cpu'
        
        # åˆå§‹åŒ–æ¨¡å—
        self.encoder = VGGEncoder(device=self.device)
        self.adain = AdaIN()
        self.decoder = Decoder().to(self.device)
        
        # åŠ è½½è§£ç å™¨æƒé‡
        if Path(decoder_path).exists():
            self.decoder.load_state_dict(torch.load(decoder_path))
            print(f"å·²åŠ è½½è§£ç å™¨: {decoder_path}")
        
        self.decoder.eval()
        
        # åˆå§‹åŒ–CLIPæ£€ç´¢å™¨
        self.retriever = CLIPStyleRetriever(
            style_dir="data/styles",
            device=self.device
        )
        self.retriever.load_features(style_features_path)
    
    def transfer(self, content_path: str, text_prompt: str, alpha: float = 1.0):
        """æ‰§è¡Œé£æ ¼è¿ç§»"""
        
        # 1. æ£€ç´¢é£æ ¼å›¾
        results = self.retriever.retrieve(text_prompt, top_k=1)
        style_name, similarity = results[0]
        style_path = self.retriever.get_style_path(style_name)
        
        # 2. åŠ è½½å›¾åƒå¹¶æå–ç‰¹å¾
        content_feat = self.encoder(content_img)
        style_feat = self.encoder(style_img)
        
        # 3. AdaIN
        stylized_feat = self.adain(content_feat, style_feat)
        
        # 4. æ’å€¼æ§åˆ¶é£æ ¼å¼ºåº¦
        stylized_feat = alpha * stylized_feat + (1 - alpha) * content_feat
        
        # 5. è§£ç 
        result = self.decoder(stylized_feat)
        
        return result, style_path, similarity`;

  const gradioApp = `import gradio as gr
import torch
from style_transfer import StyleTransferPipeline

# åˆå§‹åŒ–æ¨¡å‹
pipeline = StyleTransferPipeline(
    decoder_path="checkpoints/decoder.pth",
    style_features_path="checkpoints/style_features.pt"
)

def style_transfer_gradio(content_img, text_prompt, alpha):
    """Gradioæ¥å£å‡½æ•°"""
    
    # æ‰§è¡Œé£æ ¼è¿ç§»
    result_img, style_path, similarity = pipeline.transfer(
        content_path=content_img,
        text_prompt=text_prompt,
        alpha=alpha
    )
    
    info = f"æ£€ç´¢åˆ°çš„é£æ ¼å›¾: {style_path}\\nç›¸ä¼¼åº¦: {similarity:.4f}"
    
    return result_img, style_img, info

# åˆ›å»ºGradioç•Œé¢
demo = gr.Interface(
    fn=style_transfer_gradio,
    inputs=[
        gr.Image(type="pil", label="ä¸Šä¼ å†…å®¹å›¾"),
        gr.Textbox(label="é£æ ¼æè¿°", placeholder="ä¾‹å¦‚: van gogh starry night"),
        gr.Slider(0, 1, value=1.0, label="é£æ ¼å¼ºåº¦")
    ],
    outputs=[
        gr.Image(label="é£æ ¼åŒ–ç»“æœ"),
        gr.Image(label="åŒ¹é…çš„é£æ ¼å›¾"),
        gr.Textbox(label="æ£€ç´¢ä¿¡æ¯")
    ],
    title="æ–‡æœ¬å¼•å¯¼é£æ ¼è¿ç§» (CLIP + AdaIN)"
)

if __name__ == "__main__":
    demo.launch(share=True)`;

  const styleLabelsJson = `{
  "vangogh_starry_night.jpg": "van gogh starry night swirling sky",
  "monet_water_lilies.jpg": "monet impressionist water lilies",
  "picasso_guernica.jpg": "picasso cubism abstract geometric",
  "hokusai_wave.jpg": "hokusai great wave japanese ukiyo-e",
  "kandinsky_composition.jpg": "kandinsky abstract colorful shapes"
}`;

  const readme = `# æ–‡æœ¬å¼•å¯¼é£æ ¼è¿ç§» (CLIP + AdaIN)

åŸºäºCLIPå’ŒAdaINçš„é›¶è®­ç»ƒé£æ ¼è¿ç§»ç³»ç»Ÿ

## ç‰¹æ€§
- é›¶è®­ç»ƒ: ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
- æ–‡æœ¬å¼•å¯¼: è‡ªç„¶è¯­è¨€æè¿°é£æ ¼
- å®æ—¶æ¨ç†: å•å¼ å›¾åƒ<2ç§’

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt

### 2. é¢„å¤„ç†é£æ ¼åº“
python scripts/preprocess_styles.py

### 3. è¿è¡Œæ¼”ç¤º
python scripts/demo.py --content photo.jpg --prompt "van gogh style"

### 4. Webç•Œé¢
python app.py`;

  const tabs = [
    { id: 'structure', name: 'é¡¹ç›®ç»“æ„', icon: Folder },
    { id: 'clip', name: 'CLIPæ£€ç´¢', icon: Code },
    { id: 'adain', name: 'AdaIN', icon: Zap },
    { id: 'vgg', name: 'VGGç¼–ç å™¨', icon: Code },
    { id: 'decoder', name: 'è§£ç å™¨', icon: Code },
    { id: 'pipeline', name: 'å®Œæ•´æµç¨‹', icon: Terminal },
    { id: 'gradio', name: 'Webç•Œé¢', icon: Image },
    { id: 'readme', name: 'README', icon: FileText }
  ];

  const renderContent = () => {
    switch(activeTab) {
      case 'structure':
        return (
          <div className="space-y-4">
            <div className="bg-blue-50 p-4 rounded-lg">
              <h3 className="font-semibold text-blue-900 mb-2">ğŸ“ é¡¹ç›®ç›®å½•ç»“æ„</h3>
              <pre className="text-xs bg-white p-3 rounded overflow-x-auto font-mono">
                {projectStructure}
              </pre>
            </div>
            
            <div className="grid grid-cols-2 gap-4">
              <div className="bg-gray-50 p-3 rounded">
                <h4 className="font-semibold mb-2">requirements.txt</h4>
                <pre className="text-xs bg-white p-2 rounded overflow-x-auto h-64 font-mono">
                  {requirementsTxt}
                </pre>
              </div>
              
              <div className="bg-gray-50 p-3 rounded">
                <h4 className="font-semibold mb-2">style_labels.json</h4>
                <pre className="text-xs bg-white p-2 rounded overflow-x-auto h-64 font-mono">
                  {styleLabelsJson}
                </pre>
              </div>
            </div>
          </div>
        );
      
      case 'clip':
        return (
          <div className="space-y-3">
            <div className="bg-purple-50 p-3 rounded">
              <h3 className="font-semibold text-purple-900 mb-2">ğŸ” models/clip_retrieval.py</h3>
              <p className="text-sm text-gray-700">CLIPæ–‡æœ¬-å›¾åƒæ£€ç´¢æ¨¡å—</p>
            </div>
            <pre className="text-xs bg-gray-900 text-green-400 p-4 rounded overflow-x-auto max-h-96 font-mono">
              {clipRetrievalCode}
            </pre>
          </div>
        );
      
      case 'adain':
        return (
          <div className="space-y-3">
            <div className="bg-yellow-50 p-3 rounded">
              <h3 className="font-semibold text-yellow-900 mb-2">âš¡ models/adain.py</h3>
              <p className="text-sm text-gray-700">è‡ªé€‚åº”å®ä¾‹å½’ä¸€åŒ–æ ¸å¿ƒç®—æ³•</p>
            </div>
            <pre className="text-xs bg-gray-900 text-green-400 p-4 rounded overflow-x-auto max-h-96 font-mono">
              {adainCode}
            </pre>
          </div>
        );
      
      case 'vgg':
        return (
          <div className="space-y-3">
            <div className="bg-green-50 p-3 rounded">
              <h3 className="font-semibold text-green-900 mb-2">ğŸ¨ models/vgg.py</h3>
              <p className="text-sm text-gray-700">VGG19ç‰¹å¾æå–å™¨</p>
            </div>
            <pre className="text-xs bg-gray-900 text-green-400 p-4 rounded overflow-x-auto max-h-96 font-mono">
              {vggCode}
            </pre>
          </div>
        );
      
      case 'decoder':
        return (
          <div className="space-y-3">
            <div className="bg-red-50 p-3 rounded">
              <h3 className="font-semibold text-red-900 mb-2">ğŸ”§ models/decoder.py</h3>
              <p className="text-sm text-gray-700">ç‰¹å¾è§£ç å™¨</p>
            </div>
            <pre className="text-xs bg-gray-900 text-green-400 p-4 rounded overflow-x-auto max-h-96 font-mono">
              {decoderCode}
            </pre>
          </div>
        );
      
      case 'pipeline':
        return (
          <div className="space-y-3">
            <div className="bg-indigo-50 p-3 rounded">
              <h3 className="font-semibold text-indigo-900 mb-2">ğŸš€ style_transfer.py</h3>
              <p className="text-sm text-gray-700">å®Œæ•´é£æ ¼è¿ç§»æµç¨‹</p>
            </div>
            <pre className="text-xs bg-gray-900 text-green-400 p-4 rounded overflow-x-auto max-h-96 font-mono">
              {pipelineCode}
            </pre>
          </div>
        );
      
      case 'gradio':
        return (
          <div className="space-y-3">
            <div className="bg-pink-50 p-3 rounded">
              <h3 className="font-semibold text-pink-900 mb-2">ğŸŒ app.py</h3>
              <p className="text-sm text-gray-700">Gradio Webç•Œé¢</p>
            </div>
            <pre className="text-xs bg-gray-900 text-green-400 p-4 rounded overflow-x-auto max-h-96 font-mono">
              {gradioApp}
            </pre>
          </div>
        );
      
      case 'readme':
        return (
          <div className="space-y-3">
            <div className="bg-gray-50 p-3 rounded">
              <h3 className="font-semibold text-gray-900 mb-2">ğŸ“ README.md</h3>
            </div>
            <pre className="text-sm bg-white p-4 rounded overflow-x-auto max-h-96 font-mono whitespace-pre-wrap">
              {readme}
            </pre>
          </div>
        );
      
      default:
        return null;
    }
  };

  return (
    <div className="w-full max-w-6xl mx-auto p-6 bg-white">
      <div className="mb-6">
        <h1 className="text-3xl font-bold text-gray-900 mb-2">
          ğŸ¨ CLIP + AdaIN é£æ ¼è¿ç§»é¡¹ç›®
        </h1>
        <p className="text-gray-600">
          å®Œæ•´çš„æ–‡æœ¬å¼•å¯¼é£æ ¼è¿ç§»å®ç° - é›¶è®­ç»ƒæ–¹æ¡ˆ
        </p>
      </div>
      
      <div className="flex gap-2 mb-4 flex-wrap">
        {tabs.map(tab => {
          const Icon = tab.icon;
          return (
            <button
              key={tab.id}
              onClick={() => setActiveTab(tab.id)}
              className={`flex items-center gap-2 px-4 py-2 rounded-lg transition-colors ${
                activeTab === tab.id
                  ? 'bg-blue-600 text-white'
                  : 'bg-gray-100 text-gray-700 hover:bg-gray-200'
              }`}
            >
              <Icon size={16} />
              {tab.name}
            </button>
          );
        })}
      </div>
      
      <div className="border border-gray-200 rounded-lg p-4 bg-gray-50">
        {renderContent()}
      </div>
      
      <div className="mt-6 p-4 bg-blue-50 rounded-lg">
        <h3 className="font-semibold text-blue-900 mb-2">ğŸ’¡ ä½¿ç”¨æç¤º</h3>
        <ul className="text-sm text-blue-800 space-y-1">
          <li>â€¢ ç‚¹å‡»ä¸Šæ–¹æ ‡ç­¾åˆ‡æ¢æŸ¥çœ‹ä¸åŒæ¨¡å—çš„ä»£ç </li>
          <li>â€¢ æ‰€æœ‰ä»£ç éƒ½æ˜¯å¯ç›´æ¥è¿è¡Œçš„å®Œæ•´å®ç°</li>
          <li>â€¢ å»ºè®®æŒ‰ç…§ é¡¹ç›®ç»“æ„ â†’ CLIPæ£€ç´¢ â†’ AdaIN â†’ å®Œæ•´æµç¨‹ çš„é¡ºåºå­¦ä¹ </li>
          <li>â€¢ å¤è¯•æ¼”ç¤ºæ—¶é‡ç‚¹è®²è§£CLIPæ£€ç´¢å’ŒAdaINæ ¸å¿ƒç®—æ³•</li>
        </ul>
      </div>
    </div>
  );
};

export default ProjectStructure;